{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0003e6e3",
   "metadata": {},
   "source": [
    "# K-Means "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f11a1e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(\"__file__\"))))\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "spark = SparkSession.builder.appName(\"KMeansClustering\").getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf0f544",
   "metadata": {},
   "source": [
    "## Načítanie predspracovaných dát"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d415c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset schema:\n",
      "root\n",
      " |-- Location_Easting_OSGR: integer (nullable = true)\n",
      " |-- Location_Northing_OSGR: integer (nullable = true)\n",
      " |-- Police_Force: integer (nullable = true)\n",
      " |-- Accident_Severity: integer (nullable = true)\n",
      " |-- Number_of_Vehicles: integer (nullable = true)\n",
      " |-- Number_of_Casualties: integer (nullable = true)\n",
      " |-- Local_Authority_(District): integer (nullable = true)\n",
      " |-- 1st_Road_Number: integer (nullable = true)\n",
      " |-- Speed_limit: integer (nullable = true)\n",
      " |-- Junction_Detail: integer (nullable = true)\n",
      " |-- Junction_Control: integer (nullable = true)\n",
      " |-- 2nd_Road_Class: integer (nullable = true)\n",
      " |-- 2nd_Road_Number: integer (nullable = true)\n",
      " |-- Urban_or_Rural_Area: integer (nullable = true)\n",
      " |-- Did_Police_Officer_Attend_Scene_of_Accident: integer (nullable = true)\n",
      " |-- Vehicle_Reference: integer (nullable = true)\n",
      " |-- Casualty_Reference: integer (nullable = true)\n",
      " |-- Casualty_Severity: integer (nullable = true)\n",
      " |-- Casualty_Type: integer (nullable = true)\n",
      " |-- Vehicle_Manoeuvre: integer (nullable = true)\n",
      " |-- Junction_Location: integer (nullable = true)\n",
      " |-- Vehicle_Leaving_Carriageway: integer (nullable = true)\n",
      " |-- 1st_Point_of_Impact: integer (nullable = true)\n",
      " |-- Local_Authority_(Highway)_OHE: vector (nullable = true)\n",
      " |-- Vehicle_Type_Cat: double (nullable = true)\n",
      " |-- numerical_features_vec: vector (nullable = true)\n",
      " |-- scaled_numerical_features: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n",
      "\n",
      "Sample records:\n",
      "+---------------------------------------------------------------------------------------------------------------+-----------------+\n",
      "|features                                                                                                       |Accident_Severity|\n",
      "+---------------------------------------------------------------------------------------------------------------+-----------------+\n",
      "|[524730.0,179100.0,1.0,2.0,1.0,12.0,3220.0,30.0,6.0,2.0,3.0,315.0,1.0,1.0,2.0,1.0,3.0,1.0,7.0,8.0,0.0,1.0,8.0] |3                |\n",
      "|[524290.0,181350.0,1.0,1.0,1.0,12.0,450.0,30.0,0.0,-1.0,-1.0,0.0,1.0,1.0,1.0,1.0,2.0,11.0,2.0,0.0,0.0,4.0,10.0]|2                |\n",
      "|[524540.0,181380.0,1.0,2.0,2.0,12.0,0.0,30.0,6.0,4.0,6.0,0.0,1.0,1.0,1.0,1.0,3.0,3.0,18.0,1.0,0.0,1.0,1.0]     |3                |\n",
      "|[527760.0,179160.0,1.0,2.0,1.0,12.0,319.0,30.0,3.0,4.0,6.0,0.0,1.0,1.0,1.0,1.0,3.0,8.0,18.0,8.0,0.0,3.0,7.0]   |3                |\n",
      "|[527270.0,178660.0,1.0,2.0,1.0,12.0,0.0,30.0,6.0,4.0,6.0,0.0,1.0,2.0,1.0,1.0,3.0,9.0,18.0,8.0,0.0,1.0,8.0]     |3                |\n",
      "+---------------------------------------------------------------------------------------------------------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from preprocessing.preprocessing import preprocess_data\n",
    "\n",
    "df_train_model, df_test_model = preprocess_data()\n",
    "\n",
    "print(\"\\nDataset schema:\")\n",
    "df_train_model.printSchema()\n",
    "\n",
    "print(\"\\nSample records:\")\n",
    "df_train_model.select(\"features\", \"Accident_Severity\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff07ee61",
   "metadata": {},
   "source": [
    "## Hľadanie optimálneho počtu cluster-ov\n",
    "Na nájdenie optimálneho počtu zhlukov použijeme metódu Elbow, pričom vypočítame súčet štvorcových chýb v rámci súboru (WSSSE) pre rôzne hodnoty k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f45719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute cost (WSSSE) for different k values\n",
    "def compute_cost(df, k_values, features_col=\"features\"):\n",
    "    costs = []\n",
    "    for k in k_values:\n",
    "        kmeans = KMeans(k=k, seed=42, featuresCol=features_col)\n",
    "        model = kmeans.fit(df)\n",
    "        wssse = model.summary.trainingCost\n",
    "        costs.append(wssse)\n",
    "        print(f\"k={k}, WSSSE={wssse:.4f}\")\n",
    "    return costs\n",
    "\n",
    "# Define a range of k values to test\n",
    "k_values = list(range(2, 11))\n",
    "\n",
    "# Compute cost for each k\n",
    "print(\"Computing cost for different values of k...\")\n",
    "costs = compute_cost(df_train_model, k_values)\n",
    "\n",
    "# Plot the elbow curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_values, costs, 'bo-')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('WSSSE Cost')\n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.grid(True)\n",
    "plt.xticks(k_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c464389",
   "metadata": {},
   "source": [
    "## Trénovanie K-means modelu s optimálnym počtom cluster-ov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32c7d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the optimal k value based on the elbow plot\n",
    "optimal_k = 5  # This should be adjusted based on the elbow curve results\n",
    "\n",
    "# Train K-means with the optimal k\n",
    "kmeans = KMeans(k=optimal_k, seed=42, featuresCol=\"features\")\n",
    "model = kmeans.fit(df_train_model)\n",
    "\n",
    "# Print cluster centers\n",
    "centers = model.clusterCenters()\n",
    "print(f\"Cluster Centers for k={optimal_k}:\")\n",
    "for i, center in enumerate(centers):\n",
    "    # Print the first few dimensions of each center for brevity\n",
    "    print(f\"Cluster {i}: {center[:5]}...\")\n",
    "\n",
    "# Evaluate clustering by computing Silhouette score\n",
    "predictions = model.transform(df_train_model)\n",
    "evaluator = ClusteringEvaluator()\n",
    "silhouette = evaluator.evaluate(predictions)\n",
    "print(f\"\\nSilhouette with squared euclidean distance = {silhouette:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8287fecb",
   "metadata": {},
   "source": [
    "## Analýza cluster-ov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49998ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the model to the training data\n",
    "clustered_data = model.transform(df_train_model)\n",
    "\n",
    "# Examine the distribution of Accident Severity within each cluster\n",
    "severity_by_cluster = clustered_data.groupBy(\"prediction\", \"Accident_Severity\").count().orderBy(\"prediction\", \"Accident_Severity\")\n",
    "print(\"Distribution of Accident Severity by Cluster:\")\n",
    "severity_by_cluster.show()\n",
    "\n",
    "# Create a more detailed view of the cluster characteristics\n",
    "print(\"Cluster Summary Statistics:\")\n",
    "cluster_stats = clustered_data.groupBy(\"prediction\").agg({\n",
    "    \"Accident_Severity\": \"mean\",  # Average severity\n",
    "    \"*\": \"count\"  # Count of records in each cluster\n",
    "}).orderBy(\"prediction\")\n",
    "\n",
    "cluster_stats = cluster_stats.withColumnRenamed(\"avg(Accident_Severity)\", \"avg_severity\")\n",
    "cluster_stats = cluster_stats.withColumnRenamed(\"count(1)\", \"cluster_size\")\n",
    "cluster_stats.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7f90f6",
   "metadata": {},
   "source": [
    "## Vizualizácia cluster-ov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aa3eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import PCA\n",
    "\n",
    "# Apply PCA to reduce dimensions for visualization\n",
    "pca = PCA(k=2, inputCol=\"features\", outputCol=\"pca_features\")\n",
    "pca_model = pca.fit(clustered_data)\n",
    "result = pca_model.transform(clustered_data)\n",
    "\n",
    "# Convert to pandas for easier plotting\n",
    "pandas_df = result.select(\"pca_features\", \"prediction\", \"Accident_Severity\").toPandas()\n",
    "\n",
    "# Extract the PCA components\n",
    "pandas_df[\"pca1\"] = pandas_df[\"pca_features\"].apply(lambda x: float(x[0]))\n",
    "pandas_df[\"pca2\"] = pandas_df[\"pca_features\"].apply(lambda x: float(x[1]))\n",
    "\n",
    "# Plot the clusters\n",
    "plt.figure(figsize=(10, 8))\n",
    "for cluster in range(optimal_k):\n",
    "    cluster_data = pandas_df[pandas_df[\"prediction\"] == cluster]\n",
    "    plt.scatter(cluster_data[\"pca1\"], cluster_data[\"pca2\"], label=f\"Cluster {cluster}\", alpha=0.5)\n",
    "\n",
    "plt.title(f\"K-Means Clustering with k={optimal_k}\")\n",
    "plt.xlabel(\"PCA Component 1\")\n",
    "plt.ylabel(\"PCA Component 2\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot clusters colored by severity\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(pandas_df[\"pca1\"], pandas_df[\"pca2\"], c=pandas_df[\"Accident_Severity\"], cmap=\"viridis\", alpha=0.5)\n",
    "plt.colorbar(scatter, label=\"Accident Severity\")\n",
    "plt.title(\"Clusters by Accident Severity\")\n",
    "plt.xlabel(\"PCA Component 1\")\n",
    "plt.ylabel(\"PCA Component 2\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30bfcf0",
   "metadata": {},
   "source": [
    "## Uloženie modelu a výsledkov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900b9dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory for models if it doesn't exist\n",
    "import os\n",
    "models_dir = os.path.join(\"..\", \"models\")\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# Save the K-means model\n",
    "model_path = os.path.join(models_dir, \"kmeans_model\")\n",
    "model.save(model_path)\n",
    "print(f\"Model saved to {model_path}\")\n",
    "\n",
    "# Save a summary of the clusters\n",
    "cluster_summary = clustered_data.groupBy(\"prediction\").count().orderBy(\"prediction\")\n",
    "print(\"\\nCluster sizes:\")\n",
    "cluster_summary.show()\n",
    "\n",
    "# Export a sample of the clustered data for inspection\n",
    "sample_path = os.path.join(models_dir, \"kmeans_sample_results.csv\")\n",
    "clustered_data.select(\"prediction\", \"Accident_Severity\").sample(False, 0.01).toPandas().to_csv(sample_path, index=False)\n",
    "print(f\"Sample results saved to {sample_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
